{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(df: pd.DataFrame):\n",
    "    examples = []\n",
    "    for index, row in df.iterrows():\n",
    "        premises = row['theory']\n",
    "        premises = premises.replace('. ', '\\n ')\n",
    "        question_dict = row['questions']\n",
    "        num_q = len(question_dict)\n",
    "        questions, answers = [], []\n",
    "        for i in range(1, num_q + 1):\n",
    "            questions.append(question_dict[f'Q{i}']['question'])\n",
    "            answers.append(question_dict[f'Q{i}']['answer'])\n",
    "        examples.append(dict(\n",
    "            premises=premises,\n",
    "            conclusions=questions,\n",
    "            labels=answers\n",
    "        ))\n",
    "    return examples\n",
    "\n",
    "glove_dict = dict()\n",
    "with open('glove.6B/glove.6B.50d.txt', 'r') as fp:\n",
    "    glove = fp.read().splitlines()\n",
    "for line in glove:\n",
    "    line =  line.split(' ')\n",
    "    word, nums = line[0], np.array([float(num) for num in line[1:]])\n",
    "    glove_dict[word] = nums\n",
    "\n",
    "def sentence2vec(sentence: str) -> np.ndarray:\n",
    "    doc = nlp(sentence)\n",
    "    tokens = [word.lower_ for word in doc]\n",
    "    vecs = np.stack([glove_dict[tok] for tok in tokens if tok in glove_dict])\n",
    "    return np.mean(vecs, axis=0)\n",
    "\n",
    "label_map = {\n",
    "    True: 0,\n",
    "    False: 1,\n",
    "    'Unknown': 2\n",
    "}\n",
    "\n",
    "def get_arrays(all_examples):\n",
    "    X_list, y_list = [], []\n",
    "    for idx, example in enumerate(all_examples):\n",
    "        p_vec = sentence2vec(example['premises'])\n",
    "        c_vec_list = []\n",
    "        for conc in example['conclusions']:\n",
    "            c_vec_list.append(sentence2vec(conc))\n",
    "        pc_vecs = np.concatenate([np.expand_dims(p_vec, axis=0).repeat(len(c_vec_list), axis=0), np.stack(c_vec_list)], axis=1)\n",
    "        X_list.append(pc_vecs)\n",
    "        y_list.append(list(map(label_map.get,example['labels'])))\n",
    "    X, y = np.concatenate(X_list), np.concatenate(y_list)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhijiezhu/.pyenv/versions/3.11.8/envs/mlx/lib/python3.11/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth: 0\n",
      "0.6107670795045945\n",
      "0.6342492123061582\n",
      "0.6107670795045945\n",
      "0.591555479676545\n",
      "depth: 1\n",
      "0.5570014844136566\n",
      "0.5765397928266934\n",
      "0.5570014844136566\n",
      "0.5216864045590136\n",
      "depth: 2\n",
      "0.5480846774193548\n",
      "0.5915395250418526\n",
      "0.5480846774193548\n",
      "0.5085455247888292\n",
      "depth: 3\n",
      "0.5283102329696254\n",
      "0.5866495775280959\n",
      "0.5283102329696254\n",
      "0.4814931155940912\n",
      "depth: 5\n",
      "0.4861208187718422\n",
      "0.5602288562407689\n",
      "0.4861208187718422\n",
      "0.42738651404887423\n"
     ]
    }
   ],
   "source": [
    "clf = None\n",
    "depth = [0, 1, 2, 3, 5]\n",
    "for d in depth:\n",
    "    proofwriter_train = pd.read_json(f'proofwriter-dataset-V2020.12.3/OWA/depth-{d}/meta-train.jsonl', lines=True)\n",
    "    proofwriter_test = pd.read_json(f'proofwriter-dataset-V2020.12.3/OWA/depth-{d}/meta-test.jsonl', lines=True)\n",
    "\n",
    "    train_examples = get_dataset(proofwriter_train)\n",
    "    test_examples = get_dataset(proofwriter_test)\n",
    "\n",
    "    X_train, y_train = get_arrays(train_examples)\n",
    "    X_test, y_test = get_arrays(test_examples)\n",
    "\n",
    "    if clf is None:\n",
    "        clf = make_pipeline(StandardScaler(), SVC(gamma='auto', max_iter=10000))\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "    preds = clf.predict(X_test)\n",
    "\n",
    "    print('depth:', d)\n",
    "    print(accuracy_score(y_test, preds))\n",
    "    print(precision_score(y_test, preds, average='weighted'))\n",
    "    print(recall_score(y_test, preds, average='weighted'))\n",
    "    print(f1_score(y_test, preds, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3399014778325123\n",
      "0.11553301463272586\n",
      "0.3399014778325123\n",
      "0.17245001448855404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhijiezhu/.pyenv/versions/3.11.8/envs/mlx/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "label_map_folio = {\n",
    "    'True': 0,\n",
    "    'False': 1,\n",
    "    'Uncertain': 2\n",
    "}\n",
    "def get_arrays_folio(all_examples):\n",
    "    X_list, y_list = [], []\n",
    "    for idx, example in enumerate(all_examples):\n",
    "        p_vec = sentence2vec(example['premises'])\n",
    "        c_vec = sentence2vec(example['conclusion'])\n",
    "        pc_vecs = np.concatenate([p_vec, c_vec])\n",
    "        X_list.append(pc_vecs)\n",
    "        y_list.append(label_map_folio[example['label']])\n",
    "    X, y = np.stack(X_list), np.stack(y_list)\n",
    "    return X, y\n",
    "\n",
    "folio_train = load_dataset('yale-nlp/FOLIO', split='train')\n",
    "folio_val = load_dataset('yale-nlp/FOLIO', split='validation')\n",
    "\n",
    "X_train, y_train = get_arrays_folio(folio_train)\n",
    "X_test, y_test = get_arrays_folio(folio_val)\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, preds))\n",
    "print(precision_score(y_test, preds, average='weighted'))\n",
    "print(recall_score(y_test, preds, average='weighted'))\n",
    "print(f1_score(y_test, preds, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
